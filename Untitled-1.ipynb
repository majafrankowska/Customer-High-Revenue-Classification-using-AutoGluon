{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from autogluon.tabular import TabularPredictor, TabularDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_first_order</th>\n",
       "      <th>user_agent_brand</th>\n",
       "      <th>user_agent_os</th>\n",
       "      <th>ip_address_geopoint</th>\n",
       "      <th>ip_address_country</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pages_visited_avg</th>\n",
       "      <th>high_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000018</td>\n",
       "      <td>F</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Windows</td>\n",
       "      <td>POINT(21.0362 52.2394)</td>\n",
       "      <td>Poland</td>\n",
       "      <td>False</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000071</td>\n",
       "      <td>F</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>MacOS X</td>\n",
       "      <td>POINT(139.6895 35.6897)</td>\n",
       "      <td>Japan</td>\n",
       "      <td>True</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000440</td>\n",
       "      <td>M</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Windows</td>\n",
       "      <td>POINT(-2 8)</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>True</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000452</td>\n",
       "      <td>M</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Windows</td>\n",
       "      <td>POINT(139.6895 35.6897)</td>\n",
       "      <td>Japan</td>\n",
       "      <td>False</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000652</td>\n",
       "      <td>M</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Windows</td>\n",
       "      <td>POINT(-97.822 37.751)</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10782</th>\n",
       "      <td>zxvu44</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Windows</td>\n",
       "      <td>POINT(31.2852 30.0778)</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>False</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>zyvn97</td>\n",
       "      <td>F</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Windows</td>\n",
       "      <td>POINT(-97.822 37.751)</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>zzolm4</td>\n",
       "      <td>M</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Windows</td>\n",
       "      <td>POINT(-97.822 37.751)</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>zzw4gs</td>\n",
       "      <td>F</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Windows</td>\n",
       "      <td>POINT(-97.822 37.751)</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>zzwlin</td>\n",
       "      <td>F</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Windows</td>\n",
       "      <td>POINT(-80.0671 42.0753)</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10787 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID gender  ...  pages_visited_avg high_revenue\n",
       "0         000018      F  ...          12.000000        False\n",
       "1         000071      F  ...          12.666667        False\n",
       "2         000440      M  ...          14.200000         True\n",
       "3         000452      M  ...          15.000000        False\n",
       "4         000652      M  ...          10.000000        False\n",
       "...          ...    ...  ...                ...          ...\n",
       "10782     zxvu44      F  ...           9.000000        False\n",
       "10783     zyvn97      F  ...          14.500000        False\n",
       "10784     zzolm4      M  ...          14.000000        False\n",
       "10785     zzw4gs      F  ...          12.000000        False\n",
       "10786     zzwlin      F  ...           6.000000        False\n",
       "\n",
       "[10787 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers = pd.read_csv(\"data/customers_labeled.csv\")\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"high_revenue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = customers.drop([label], axis=1)\n",
    "y = customers[label]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train, y_train], axis=1),\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_train = TabularDataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250513_130217\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.12.5\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          16\n",
      "Memory Avail:       5.29 GB / 15.69 GB (33.7%)\n",
      "Disk Space Avail:   197.99 GB / 471.56 GB (42.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 15s of the 60s of remaining time (25%).\n",
      "2025-05-13 15:02:18,937\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-05-13 15:02:23,424\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"c:\\Users\\s24331\\Desktop\\PUM_01\\AutogluonModels\\ag-20250513_130217\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Beginning AutoGluon training ... Time limit = 6s\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m AutoGluon will save models to \"c:\\Users\\s24331\\Desktop\\PUM_01\\AutogluonModels\\ag-20250513_130217\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Train Data Rows:    9588\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Train Data Columns: 9\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Label Column:       high_revenue\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tAvailable Memory:                    4843.22 MB\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tTrain Data (Original)  Memory Usage: 3.29 MB (0.1% of available memory)\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\t('bool', [])   : 1 | ['campaign']\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\t('float', [])  : 2 | ['age_first_order', 'pages_visited_avg']\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\t('object', []) : 6 | ['customerID', 'gender', 'user_agent_brand', 'user_agent_os', 'ip_address_geopoint', ...]\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\t('category', [])  : 6 | ['customerID', 'gender', 'user_agent_brand', 'user_agent_os', 'ip_address_geopoint', ...]\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\t('float', [])     : 2 | ['age_first_order', 'pages_visited_avg']\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t\t('int', ['bool']) : 1 | ['campaign']\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t9 features in original data used to generate 9 features in processed data.\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.22 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'GBM'}}],\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t'CAT': [{'ag_args': {'name_suffix': 'CAT'}}],\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t'XGB': [{'ag_args': {'name_suffix': 'XGB'}}],\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t'RF': [{'ag_args': {'name_suffix': 'RF'}}],\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t'NN_TORCH': [{'ag_args': {'name_suffix': 'NN_TORCH'}}],\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Fitting 5 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Fitting model: LightGBMGBM_BAG_L1 ... Training model for up to 3.70s of the 5.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t0.9089\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t1.37s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_ray_fit pid=644)\u001b[0m \tRan out of time, early stopping on iteration 226. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=644)\u001b[0m \t[120]\tvalid_set's binary_error: 0.0900751\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 5.55s of the -3.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tEnsemble Weights: {'LightGBMGBM_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t0.9089\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t0.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Fitting 5 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 5.55s of the -3.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \tEnsemble Weights: {'LightGBMGBM_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t0.9089\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m AutoGluon training complete, total runtime = 8.97s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13912.5 rows/s (1199 batch size)\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (9588 rows).\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m \t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\s24331\\Desktop\\PUM_01\\AutogluonModels\\ag-20250513_130217\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=14600)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   LightGBMGBM_BAG_L1       0.908257   0.908949    accuracy        0.769945       0.085155  1.366852                 0.769945                0.085155           1.366852            1       True          1\n",
      "1  WeightedEnsemble_L2       0.908257   0.908949    accuracy        0.790125       0.093365  1.368860                 0.020181                0.008210           0.002008            2       True          2\n",
      "2  WeightedEnsemble_L3       0.908257   0.908949    accuracy        0.800567       0.085155  1.374080                 0.030623                0.000000           0.007229            3       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t21s\t = DyStack   runtime |\t39s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 39s\n",
      "AutoGluon will save models to \"c:\\Users\\s24331\\Desktop\\PUM_01\\AutogluonModels\\ag-20250513_130217\"\n",
      "Train Data Rows:    10787\n",
      "Train Data Columns: 9\n",
      "Label Column:       high_revenue\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3755.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.69 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])   : 1 | ['campaign']\n",
      "\t\t('float', [])  : 2 | ['age_first_order', 'pages_visited_avg']\n",
      "\t\t('object', []) : 6 | ['customerID', 'gender', 'user_agent_brand', 'user_agent_os', 'ip_address_geopoint', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['customerID', 'gender', 'user_agent_brand', 'user_agent_os', 'ip_address_geopoint', ...]\n",
      "\t\t('float', [])     : 2 | ['age_first_order', 'pages_visited_avg']\n",
      "\t\t('int', ['bool']) : 1 | ['campaign']\n",
      "\t0.3s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.25 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.4s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'GBM'}}],\n",
      "\t'CAT': [{'ag_args': {'name_suffix': 'CAT'}}],\n",
      "\t'XGB': [{'ag_args': {'name_suffix': 'XGB'}}],\n",
      "\t'RF': [{'ag_args': {'name_suffix': 'RF'}}],\n",
      "\t'NN_TORCH': [{'ag_args': {'name_suffix': 'NN_TORCH'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 5 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMGBM_BAG_L1 ... Training model for up to 25.61s of the 38.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.12%)\n",
      "\t0.9093\t = Validation score   (accuracy)\n",
      "\t1.69s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestRF_BAG_L1 ... Training model for up to 16.88s of the 29.70s of remaining time.\n",
      "c:\\Users\\s24331\\Desktop\\PUM_01\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.9017\t = Validation score   (accuracy)\n",
      "\t1.93s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: CatBoostCAT_BAG_L1 ... Training model for up to 14.50s of the 27.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=7.77%)\n",
      "\tTime limit exceeded... Skipping CatBoostCAT_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 38.44s of the 10.36s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMGBM_BAG_L1': 1.0}\n",
      "\t0.9093\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 5 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMGBM_BAG_L2 ... Training model for up to 10.31s of the 10.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.16%)\n",
      "2025-05-13 15:03:12,035\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=8720, ip=127.0.0.1)\n",
      "  File \"python\\\\ray\\\\_raylet.pyx\", line 1895, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\s24331\\Desktop\\PUM_01\\.venv\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\s24331\\Desktop\\PUM_01\\.venv\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\s24331\\Desktop\\PUM_01\\.venv\\Lib\\site-packages\\autogluon\\tabular\\models\\catboost\\catboost_model.py\", line 226, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "2025-05-13 15:03:12,040\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=13644, ip=127.0.0.1)\n",
      "  File \"python\\\\ray\\\\_raylet.pyx\", line 1895, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\s24331\\Desktop\\PUM_01\\.venv\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\s24331\\Desktop\\PUM_01\\.venv\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\s24331\\Desktop\\PUM_01\\.venv\\Lib\\site-packages\\autogluon\\tabular\\models\\catboost\\catboost_model.py\", line 226, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "2025-05-13 15:03:13,040\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-05-13 15:03:13,040\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-05-13 15:03:13,048\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-05-13 15:03:13,048\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-05-13 15:03:13,048\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9096\t = Validation score   (accuracy)\n",
      "\t2.4s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestRF_BAG_L2 ... Training model for up to 2.52s of the 2.52s of remaining time.\n",
      "c:\\Users\\s24331\\Desktop\\PUM_01\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.9079\t = Validation score   (accuracy)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: CatBoostCAT_BAG_L2 ... Training model for up to 1.17s of the 1.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=7.96%)\n",
      "\tTime limit exceeded... Skipping CatBoostCAT_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 38.44s of the -4.98s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMGBM_BAG_L2': 1.0}\n",
      "\t0.9096\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 43.88s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 4819.3 rows/s (1349 batch size)\n",
      "Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
      "Calibrating decision threshold to optimize metric accuracy | Checking 51 thresholds...\n",
      "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
      "\tBase Threshold: 0.500\t| val: 0.9096\n",
      "\tBest Threshold: 0.500\t| val: 0.9096\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\s24331\\Desktop\\PUM_01\\AutogluonModels\\ag-20250513_130217\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label, eval_metric=\"accuracy\").fit(\n",
    "    train_data=td_train,\n",
    "    time_limit=60,\n",
    "    presets=\"best_quality\",\n",
    "    hyperparameters={\n",
    "    \"GBM\": {\"extra_trees\": True, \"ag_args\": {\"name_suffix\": \"GBM\"}},\n",
    "    \"CAT\": {\"ag_args\": {\"name_suffix\": \"CAT\"}},\n",
    "    \"XGB\": {\"ag_args\": {\"name_suffix\": \"XGB\"}},\n",
    "    \"RF\": {\"ag_args\": {\"name_suffix\": \"RF\"}},\n",
    "    \"NN_TORCH\": {\"ag_args\": {\"name_suffix\": \"NN_TORCH\"}}}\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_test= TabularDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(td_test.drop(columns=[label]), as_pandas=True)\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = predictor.predict_proba(td_test, as_pandas=True)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(td_test, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(td_test[label], y_pred)\n",
    "ConfusionMatrixDisplay(cm, display_labels=predictor.classes_).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
